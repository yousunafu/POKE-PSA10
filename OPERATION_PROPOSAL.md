# 1日1回更新での運用案（運営費OK前提）

上司依頼・1日1回更新・運営費可の前提で、いくつかの運用パターンを提案します。  
**表示は Streamlit ではなく Web ページ（フロント＋API）で運用する前提**です。

---

## 前提の整理

| 項目 | 内容 |
|------|------|
| **更新頻度** | 1日1回（例: 毎朝6時など） |
| **やること** | ① scrape_otachu.py → ② scrape_rush.py → ③ merged_card_data.csv が最新になる |
| **かかる時間** | おたちゅう 数分 ＋ ラッシュ 約20〜40分（400件×待機など） |
| **表示** | **Web ページ**（frontend: Vite/React ＋ backend: FastAPI が `merged_card_data.csv` を読んで API 提供） |

---

## 提案1: 社内PC + タスクスケジューラ（コスト最小）

**構成**

- 社内の1台のPCを「更新用」に決める
- そのPCで **毎日決まった時刻** にスクレイプを実行
- 同じPCで **Web サーバー**（backend: FastAPI + frontend のビルド結果を配信）を起動し、社内LANでブラウザからアクセス

**やること**

1. Windows なら「タスクのスケジュール」、Mac なら `launchd` で「毎日 例: 6:00」に以下を実行するバッチを作る  
   - `python3 scrape_otachu.py`  
   - `python3 scrape_rush.py`  
   - （必要なら）backend（uvicorn）と frontend 配信の起動も同じバッチに含める
2. そのPCは **毎日その時刻に起動している** ようにする（スリープしない・電源ON）

**メリット**  
・追加コストほぼゼロ  
・設定が分かりやすい  

**デメリット**  
・そのPCが落ちている・スリープだと更新されない  
・外出先からは見られない（VPN等は別途）  

**向いている人**  
・社内だけで使う  
・「更新用PC」を1台決められる  

---

## 提案2: クラウドVM1台で全部やる（シンプル・月数千円）

**構成**

- **1台のVM**（**AWS Lightsail** / EC2 / GCP Compute Engine / さくらVPS / ConoHa など）を借りる
- そのVM上で  
  - 毎日 cron で `scrape_otachu.py` → `scrape_rush.py` を実行  
  - 常時 **backend（FastAPI / uvicorn）** を動かし、**frontend のビルド結果** を nginx などで配信（または backend で静的ファイルも配信）  
- ブラウザでは **VMのIP or ドメイン** で Web ページにアクセス

**やること**

1. VM に Python + Node（frontend ビルド用）+ Playwright + Chromium を入れる  
2. プロジェクト（frontend, backend, scrape_*.py）を置き、frontend を `npm run build` でビルド  
3. cron で例: `0 6 * * * cd /path/to/app && python3 scrape_otachu.py && python3 scrape_rush.py`  
4. backend（uvicorn）と nginx（または静的配信）を systemd で起動し、再起動しても自動で立ち上がるようにする  

**目安コスト**  
・さくらVPS / ConoHa: 月 500〜1,000円程度  
・**AWS Lightsail 2GB**: 月 **約 $10（約1,500円）** — 料金が分かりやすく、AWS の入門にも向く  
・AWS EC2 小さいインスタンス: 月 1,000〜3,000円程度  

**Lightsail 2GB について**  
・**2GB メモリ** で、このアプリの運用には十分。  
・常時動かす backend + nginx は軽い。スクレイプ実行時だけ Playwright（Chromium）が動くが、2GB でヘッドレスブラウザも動作可能。  
・スクレイプ中にメモリが一時的にきつい場合は、Swap を 1GB 程度用意しておくと安心。  
・EC2 より画面がシンプルで、固定料金なので「月いくら」が分かりやすい。

**メリット**  
・24時間どこからでもアクセス可能  
・PCの電源に依存しない  
・「1台でスクレイプ＋表示」まで完結  

**デメリット**  
・VMの初期設定・運用の手間がある  
・Playwright が動くだけのメモリは欲しい（**2GB あれば問題なし**）  

**向いている人**  
・外からも見たい  
・「サーバー1台で全部まとめたい」  
・AWS を使いたいが EC2 は重いと感じる → **Lightsail 2GB がおすすめ**  

---

## 提案3: スクレイプ用サーバー + Web ホスティング（役割分担）

**構成**

- **スクレイプ専用**: 小さいVM or 常時動くCI（GitHub Actions は時間制限に注意）で、毎日 `scrape_otachu.py` → `scrape_rush.py` を実行  
- **出力**: 生成した `merged_card_data.csv` を **GitHub のリポジトリ** にコミット＆プッシュ、または **S3 など** にアップロード  
- **表示**: **フロントは Vercel など**、**API は Railway / Render など** にデプロイ。API は CSV を GitHub raw URL または S3 から取得するように変更  

**やること**

1. スクレイプ実行環境（VM or 自前 runner）で cron により毎日スクレイプ実行  
2. 出力 CSV を GitHub の `main` に push、または S3 にアップロード  
3. frontend を Vercel に、backend を Railway / Render にデプロイ（backend の CSV 参照先を環境変数で GitHub raw URL や S3 URL に設定）  
4. backend の `CSV_PATH` を「リモートURL」対応にする（起動時に CSV をダウンロードして読む、または URL から直接読む）  

**目安コスト**  
・Vercel（フロント）: 無料枠あり  
・Railway / Render（API）: 無料枠 or 月 500〜1,500円程度  
・スクレイプ用VM: 月 500〜2,000円程度  
・S3 を使う場合: 月数十円〜百円程度  

**メリット**  
・Web ページ（フロント＋API）はマネージドなホスティングに任せられる  
・スクレイプと表示を分けられる（スクレイプが重くてもアプリは軽い）  

**デメリット**  
・「CSVをどこに置くか」「API がそのURLを読む」の設定が必要  
・GitHub にCSVをpushする場合は、リポジトリがやや肥大化する（日次なら許容範囲のことが多い）  

**向いている人**  
・「Web ページはクラウドで見せたいが、スクレイプは自前サーバーで回したい」  

---

## 提案4: 全部クラウド + マネージド感を出す（AWS例・月数千円）

**構成**

- **スクレイプ**: AWS EC2 小さいインスタンス or Lambda + コンテナ で毎日実行（EventBridge でスケジュール）  
- **CSVの置き場**: S3 バケットに `merged_card_data.csv` を保存  
- **Web ページ**: backend（FastAPI）を ECS Fargate や App Runner で動かし、frontend は S3 + CloudFront で配信、または EC2 上で両方動かす  
- **アクセス**: ALB / App Runner / CloudFront のURLで公開（必要なら認証も追加）  

**やること**

1. S3 バケット作成、スクレイプ結果をここに書き出す  
2. スクレイプジョブを EventBridge で毎日実行（EC2 なら cron でも可）  
3. backend をコンテナ化し、起動時に S3 から CSV を取得するか、S3 の URL を読むように変更  
4. frontend をビルドして S3 + CloudFront で配信、backend を ECS / App Runner でデプロイし、URL を発行  

**目安コスト**  
・EC2 小さい + S3 + アプリ用: 月 3,000〜8,000円程度（利用量による）  

**メリット**  
・AWS で統一できる  
・S3 に履歴を残せる（過去のCSVを取っておくなど）  
・スケールや監視をAWSの機能でやりやすい  

**デメリット**  
・設計・設定が一番重い  
・このアプリ規模だと「やりすぎ」に感じる可能性あり  

**向いている人**  
・会社でAWS利用が前提  
・将来の拡張や監査を考えたい  

---

## 比較まとめ

| 提案 | 目安コスト | 手軽さ | どこからでも見る | おすすめ度 |
|------|------------|--------|------------------|------------|
| 1. 社内PC + スケジューラ | ほぼ0円 | ◎ | × | 社内専用なら◎ |
| 2. VM1台で全部 | 月500〜3000円 | ○ | ◎ | バランス◎ |
| 3. スクレイプ用 + Web ホスティング（Vercel+API） | 月500〜2000円 | △ | ◎ | 役割分けしたいとき |
| 4. AWS で一式 | 月3000〜8000円 | △ | ◎ | AWS方針なら |

---

## おすすめの選び方

- **「社内だけでよく、コストは抑えたい」**  
  → **提案1**（社内PC + タスクスケジューラ）

- **「外からも見たいし、1日1回の更新を確実に回したい」**  
  → **提案2**（VM1台でスクレイプ＋Web ページ）が設定もコストもバランス良い

- **「Web ページはクラウドのホスティングに任せたい」**  
  → **提案3**（スクレイプ用サーバー + Vercel / Railway など）

- **「会社でAWSを使う方針」**  
  → **提案4**（AWSでスクレイプ・S3・Web ページを一式）

---

## 共通でやっておくとよいこと

どの案でも以下があると運用が楽です。

1. **ログ**  
   - スクレイプを実行するバッチ／cron で、標準出力やエラーをファイルに残す（例: `>> /var/log/otachu_rush.log 2>&1`）。

2. **失敗時の通知（任意）**  
   - スクレイプが異常終了したときにメールやSlackで知らせる（cron の戻り値を見て簡易スクリプトで送るなど）。

3. **CSVのバックアップ**  
   - 毎日できた `merged_card_data.csv` を日付付きでコピーしておくと、過去の状態を比較・復元しやすい。

4. **実行時刻**  
   - ラッシュのスクレイプが 20〜40 分かかるので、「毎日 6:00 開始」など、誰も使わない時間帯に設定すると安全。

必要なら、選んだ案に合わせて「cronの具体例」「app.py でS3/GitHubのCSVを読む書き方」なども別ドキュメントでまとめられます。
